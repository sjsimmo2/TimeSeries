[["arima.html", "Chapter 4 ARIMA 4.1 Stationarity 4.2 Correlation Functions 4.3 AutoRegressive Models (AR) 4.4 Moving Average model (MA) 4.5 White noise 4.6 Trending Series 4.7 Fitting ARIMA models 4.8 Python Code for ARMA/ARIMA models", " Chapter 4 ARIMA We will now be switching over to doing ARMA/ARIMA models!! There are a number of different concepts you will need in order to do this type of modeling. 4.1 Stationarity Before we can try to model the dependency structure (the AR and MA terms), we must first have a stationarity! The ADF test is one of the most well-known and accepted test for testing stationarity. There are several packages that will do this for you, however, below, I am focusing on the ADF test within the package aTSA. Quotes.ts&lt;-ts(Quotes$Quotes,start=2002,frequency=12) autoplot(Quotes.ts)+labs(title=&quot;Time Series of Daily Stock quotes&quot;, x=&quot;Time&quot;, y=&quot;Quotes&quot;) The following code produces output similar to the output seen in SAS (under the tau test). # Perform the ADF test (k=0) aTSA::adf.test(Quotes.ts) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -0.3061 0.550 ## [2,] 1 -0.5980 0.458 ## [3,] 2 -0.0632 0.620 ## [4,] 3 -0.0950 0.611 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -2.66 0.0939 ## [2,] 1 -3.42 0.0192 ## [3,] 2 -2.45 0.1608 ## [4,] 3 -2.36 0.1943 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -2.62 0.3212 ## [2,] 1 -3.36 0.0772 ## [3,] 2 -2.41 0.4012 ## [4,] 3 -2.29 0.4463 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 4.2 Correlation Functions The Acf and the Pacf in R will calculate the autocorrelation (up to the lag you specify) and the partial autocorrelation, respectively. You can either output these values to look at them or plot them (see code below). acf1=Acf(Y, lag=10)$acf pacf1=Pacf(Y, lag=10)$acf index1=seq(1,length(pacf1)) all.dat=data.frame(cbind(acf1[2:11],pacf1,index1)) colnames(all.dat)=c(&quot;acf&quot;,&quot;pacf&quot;,&quot;index&quot;) ggplot(all.dat,aes(x=factor(index),y=acf))+geom_col()+labs(x=&quot;Lags&quot;) 4.3 AutoRegressive Models (AR) AutoRegressive (AR) models involve modeling the lags of Y. We can write an autoregressive model as \\[ Y_{t} = c + \\phi_{1}Y_{t-1}+\\phi_{2}Y_{t-2}+...\\phi_{p}Y_{t-p}+\\epsilon_{t} \\] Where there are p lags of Y. Below is the code to fit an AR(2) model. The order in the Arima function needs the p,d,q values (p=# of AR terms, d=how many differences should be taken and q=# of MA terms). ggAcf(Y) ggPacf(Y) Y.ts &lt;- ts(Y) Y.ARIMA &lt;- Arima(Y.ts, order=c(2,0,0)) ggAcf(Y.ARIMA$residuals) ggPacf(Y.ARIMA$residuals) 4.4 Moving Average model (MA) Moving average (MA) models involve modeling the lags of the error. We can write a moving average model as \\[ Y_{t} = c - \\theta_{1}\\epsilon_{t-1}-\\theta_{2}\\epsilon_{t-2}-...\\theta_{q}\\epsilon_{t-q}+\\epsilon_{t} \\] Where there are q lags of \\(\\epsilon\\). Below is code to fit an MA(2) model. ggAcf(x) ggPacf(x) x.ts &lt;- ts(x) x.ARIMA &lt;- Arima(x.ts, order=c(0,0,2)) summary(x.ARIMA) ## Series: x.ts ## ARIMA(0,0,2) with non-zero mean ## ## Coefficients: ## ma1 ma2 mean ## -0.2460 0.4772 0.0250 ## s.e. 0.0857 0.0923 0.0567 ## ## sigma^2 = 0.2207: log likelihood = -65.1 ## AIC=138.2 AICc=138.63 BIC=148.62 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0008828966 0.4627151 0.3808289 74.99115 114.4434 0.5453401 ## ACF1 ## Training set -0.002299708 ggAcf(x.ARIMA$residuals) ggPacf(x.ARIMA$residuals) 4.5 White noise For residuals to exhibit white noise, they must be independent and normally distributed with mean 0 and constant variance. You already know how to assess normality and constant variance, however, we need to focus on assessing independence. We can assess if there is significant dependence through the Ljung-Box test. The hypotheses being tested are \\[H_{0}:No\\quad significant\\quad autocorrelation\\\\ H_{A}:Significant\\qquad autocorrletion \\] This should be assessed on a stationary time series. Looking at a stationary time series, going back 10 lags should be sufficient (this will be different when we get to seasonal models). We would like for all of the p-values (for lags 1-10) to be insignificant (large p-values). However, keep in mind that sample size will matter when assessing significance. White.LB &lt;- rep(NA, 10) for(i in 1:10){ White.LB[i] &lt;- Box.test(Y, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 0)$p.value } white.dat=data.frame(cbind(White.LB,index1)) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Ljung-Box test p-values&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;)+coord_cartesian(ylim = c(0, 0.025)) ####Fit appropriate model Y.ARIMA=Arima(Y,order=c(2,0,0)) White.LB &lt;- rep(NA, 10) for(i in 3:10){ White.LB[i] &lt;- Box.test(Y.ARIMA$residuals, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 2)$p.value } white.dat=data.frame(cbind(White.LB[3:10],index1[3:10])) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Ljung-Box test when there is white noise&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;) 4.6 Trending Series If the series is trending then it is NOT stationary. You will NEED to do something to the series in order to make it stationary!! You will either fit a linear regression line (then use the residuals to model dependencies) or take differences and use the differenced series to model dependencies. We will be using the Ebay stock data of Daily High (however, this data has missing values!!). If you do not impute missing values, it simply ignores the missing values (could create an issue). I would recommend FIRST imputing those values BEFORE doing the ADF test (in the na_interpolation algorithm, missing values are imputed). Daily.High &lt;- ts(Ebay$DailyHigh) ###NOT appropriate since there are missing values!! aTSA::adf.test(Daily.High) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 0.410 0.762 ## [2,] 1 0.157 0.689 ## [3,] 2 0.254 0.717 ## [4,] 3 0.327 0.738 ## [5,] 4 0.396 0.758 ## [6,] 5 0.431 0.768 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -1.79 0.409 ## [2,] 1 -1.99 0.331 ## [3,] 2 -1.90 0.366 ## [4,] 3 -1.89 0.372 ## [5,] 4 -1.88 0.375 ## [6,] 5 -1.91 0.365 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -1.74 0.687 ## [2,] 1 -2.09 0.538 ## [3,] 2 -1.94 0.600 ## [4,] 3 -1.87 0.632 ## [5,] 4 -1.81 0.657 ## [6,] 5 -1.80 0.662 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 ggplot_na_distribution(Daily.High)+labs(y=&quot;Stock prices for Ebay&quot;) # Interpolate the missing observations in this data set Daily.High&lt;-Daily.High %&gt;% na_interpolation(option = &quot;spline&quot;) autoplot(Daily.High)+labs(title=&quot;Daily high stock quotes&quot;,x=&quot;Time&quot;,y=&quot;Quotes&quot;) # Perform an ADF test aTSA::adf.test(Daily.High) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 0.414 0.763 ## [2,] 1 0.148 0.687 ## [3,] 2 0.266 0.720 ## [4,] 3 0.330 0.739 ## [5,] 4 0.385 0.755 ## [6,] 5 0.434 0.769 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -1.80 0.405 ## [2,] 1 -2.01 0.324 ## [3,] 2 -1.91 0.364 ## [4,] 3 -1.90 0.367 ## [5,] 4 -1.90 0.368 ## [6,] 5 -1.92 0.361 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -1.76 0.679 ## [2,] 1 -2.13 0.520 ## [3,] 2 -1.96 0.595 ## [4,] 3 -1.89 0.622 ## [5,] 4 -1.84 0.642 ## [6,] 5 -1.82 0.653 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 ### Definitely a Random Walk!! How do we fit each situation? If the series is stationary about the line, we need to fit a line (and then model the AR and MA terms on the residuals). If series is a random walk with drift, then need to take differences. Here is the R code for each situation. ###Fitting a regression line... time.high=seq(1,length(Daily.High)) ARIMA.line=Arima(Daily.High,order=c(0,0,0),xreg=time.high) summary(ARIMA.line) ## Series: Daily.High ## Regression with ARIMA(0,0,0) errors ## ## Coefficients: ## intercept xreg ## 58.1845 0.3942 ## s.e. 4.3071 0.0234 ## ## sigma^2 = 1477: log likelihood = -1610.58 ## AIC=3227.17 AICc=3227.24 BIC=3238.45 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 4.157949e-12 38.31299 31.05748 -31.93382 49.92292 6.324794 ## ACF1 ## Training set 0.9819061 #### Now model residuals (ARIMA.line$residuals) with AR and MA terms...can also send residuals through an automatic procedure to help! ####Fitting a random walk with drift ARIMA.RW=Arima(Daily.High,order=c(0,1,0)) summary(ARIMA.RW) ## Series: Daily.High ## ARIMA(0,1,0) ## ## sigma^2 = 47.76: log likelihood = -1062.6 ## AIC=2127.21 AICc=2127.22 BIC=2130.96 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 0.4779789 6.900166 4.895049 0.4782673 4.541625 0.9968669 0.2026237 #### automatic procedure will determine if you need differencing or not! 4.7 Fitting ARIMA models We can use an automatic procedure to help us find a model. For this illustration, we will be using the mean of the maximum velocity in the hurricane data set. This data also has some missing values which we need to look into first. max.velocity=hurricane$MeanVMax ggplot_na_distribution(max.velocity)+labs(y=&quot;Mean Max Velocity&quot;) This is yearly data and the reason those values are missing is because there were no hurricanes recorded for that year. Since there is no trend (nor seasonality), I am going to remove these NA values and then run the Dickey-Fuller test. max.velocity=na.omit(max.velocity) hurrican.ts=ts(max.velocity) aTSA::adf.test(hurrican.ts) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -0.8242 0.384 ## [2,] 1 -0.4391 0.517 ## [3,] 2 -0.2585 0.569 ## [4,] 3 -0.1254 0.607 ## [5,] 4 -0.0692 0.623 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -10.69 0.01 ## [2,] 1 -7.69 0.01 ## [3,] 2 -5.09 0.01 ## [4,] 3 -4.09 0.01 ## [5,] 4 -3.62 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -11.37 0.01 ## [2,] 1 -8.37 0.01 ## [3,] 2 -5.70 0.01 ## [4,] 3 -4.67 0.01 ## [5,] 4 -4.23 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 Series is stationary!! Lets see if there is any significant dependecies here index1=seq(1,10) White.LB &lt;- rep(NA, 10) for(i in 1:10){ White.LB[i] &lt;- Box.test(hurrican.ts, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 0)$p.value } white.dat=data.frame(cbind(White.LB[1:10],index1[1:10])) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Hurricane data&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;) There is definitely something to be modeled here!! Lets try an automated search first model1=auto.arima(hurrican.ts) model2=auto.arima(hurrican.ts,d=0) Lets take a look at ACF and PACF plots and see how well we do manually.. ggAcf(hurrican.ts) ggPacf(hurrican.ts) Using the graphs and some trial and error, here was the model I chose model3=Arima(hurrican.ts,order=c(2,0,3)) summary(model3) ## Series: hurrican.ts ## ARIMA(2,0,3) with non-zero mean ## ## Coefficients: ## ar1 ar2 ma1 ma2 ma3 mean ## 0.7921 0.1100 -0.7257 -0.1803 0.1578 91.4046 ## s.e. 0.4161 0.3958 0.4094 0.3583 0.0791 1.8812 ## ## sigma^2 = 94.76: log likelihood = -569.79 ## AIC=1153.58 AICc=1154.34 BIC=1174.88 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.07215997 9.544078 7.471114 -1.024043 8.28476 0.7050813 ## ACF1 ## Training set -0.0003383851 Comparing the ACF and PACF plots for these models: ggAcf(model1$residuals,lag.max = 10) ggPacf(model1$residuals,lag.max = 10) ggAcf(model2$residuals,lag.max = 10) ggPacf(model2$residuals,lag.max = 10) ggAcf(model3$residuals,lag.max = 10) ggPacf(model3$residuals,lag.max = 10) Lets take a look at white noise for each model: index1=seq(1,10) White.LB &lt;- rep(NA, 10) for(i in 2:10){ White.LB[i] &lt;- Box.test(model1$residuals, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 1)$p.value } white.dat=data.frame(cbind(White.LB[2:10],index1[2:10])) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Model 1&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;) White.LB &lt;- rep(NA, 10) for(i in 3:10){ White.LB[i] &lt;- Box.test(model2$residuals, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 2)$p.value } white.dat=data.frame(cbind(White.LB[3:10],index1[3:10])) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Model 2&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;) White.LB &lt;- rep(NA, 10) for(i in 6:10){ White.LB[i] &lt;- Box.test(model3$residuals, lag=i, type=&quot;Ljung-Box&quot;, fitdf = 5)$p.value } white.dat=data.frame(cbind(White.LB[6:10],index1[6:10])) colnames(white.dat)=c(&quot;pvalues&quot;,&quot;Lag&quot;) ggplot(white.dat,aes(x=factor(Lag),y=pvalues))+geom_col()+labs(title=&quot;Model 3&quot;,x=&quot;Lags&quot;,y=&quot;p-values&quot;) ggplot(data =hurrican.ts, aes(x = model1$residuals)) + geom_histogram() + labs(title = &#39;Histogram of Residuals for Model 1&#39;, x = &#39;Residuals&#39;, y = &#39;Frequency&#39;) ## Don&#39;t know how to automatically pick scale for object of type ts. Defaulting to continuous. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(data =hurrican.ts, aes(x = model2$residuals)) + geom_histogram() + labs(title = &#39;Histogram of Residuals for Model 2&#39;, x = &#39;Residuals&#39;, y = &#39;Frequency&#39;) ## Don&#39;t know how to automatically pick scale for object of type ts. Defaulting to continuous. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(data =hurrican.ts, aes(x = model3$residuals)) + geom_histogram() + labs(title = &#39;Histogram of Residuals for Model 3&#39;, x = &#39;Residuals&#39;, y = &#39;Frequency&#39;) ## Don&#39;t know how to automatically pick scale for object of type ts. Defaulting to continuous. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. You can now forecast the data with these models: forecast::forecast(model1, h = 10) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 156 94.59774 82.06430 107.1312 75.42950 113.7660 ## 157 94.59774 82.00783 107.1877 75.34314 113.8524 ## 158 94.59774 81.95162 107.2439 75.25716 113.9383 ## 159 94.59774 81.89565 107.2998 75.17157 114.0239 ## 160 94.59774 81.83993 107.3556 75.08635 114.1091 ## 161 94.59774 81.78445 107.4110 75.00151 114.1940 ## 162 94.59774 81.72921 107.4663 74.91703 114.2785 ## 163 94.59774 81.67421 107.5213 74.83291 114.3626 ## 164 94.59774 81.61944 107.5760 74.74914 114.4463 ## 165 94.59774 81.56490 107.6306 74.66573 114.5298 autoplot(forecast::forecast(model1, h = 10)) autoplot(forecast::forecast(model2, h = 10)) autoplot(forecast::forecast(model3, h = 10)) 4.8 Python Code for ARMA/ARIMA models import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame from statsmodels.tsa.stattools import adfuller ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.23.2) ## warnings.warn(f&quot;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion} is required for this version of &quot; from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA quotes=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\fpp_insurance.csv&quot;) y=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\ar2.csv&quot;) result=adfuller(quotes[&quot;Quotes&quot;]) print(f&#39;ADF p-value: {result[1]}&#39;) ## ADF p-value: 0.010194998749727959 plot_acf(quotes[&quot;Quotes&quot;],lags=12) pyplot.show() plot_pacf(quotes[&quot;Quotes&quot;],lags=12) pyplot.show ## &lt;function make_python_function.&lt;locals&gt;.python_function at 0x00000000630BA940&gt; model = ARIMA(y, order=(2,0,0)) model_fit = model.fit() print(model_fit.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Y No. Observations: 1000 ## Model: ARIMA(2, 0, 0) Log Likelihood -3695.014 ## Date: Wed, 24 Aug 2022 AIC 7398.028 ## Time: 10:54:51 BIC 7417.659 ## Sample: 0 HQIC 7405.489 ## - 1000 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## const -0.1365 0.420 -0.325 0.745 -0.960 0.687 ## ar.L1 0.6406 0.030 21.165 0.000 0.581 0.700 ## ar.L2 -0.3759 0.030 -12.466 0.000 -0.435 -0.317 ## sigma2 94.7853 4.193 22.604 0.000 86.567 103.004 ## =================================================================================== ## Ljung-Box (Q): 28.18 Jarque-Bera (JB): 0.26 ## Prob(Q): 0.92 Prob(JB): 0.88 ## Heteroskedasticity (H): 1.04 Skew: -0.03 ## Prob(H) (two-sided): 0.73 Kurtosis: 3.05 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). residuals = DataFrame(model_fit.resid) residuals.plot() pyplot.show() print(residuals.describe()) ## 0 ## count 1000.000000 ## mean -0.001313 ## std 9.747534 ## min -33.282545 ## 25% -6.475670 ## 50% 0.117391 ## 75% 6.510636 ## max 30.318100 plot_acf(residuals,lags=12) pyplot.show() plot_pacf(residuals,lags=12) pyplot.show() Checking for white noise: The first value in the Ljung-Box test is the test statistic and the second value is the p-value. import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame import statsmodels.api as sm from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA quotes=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\fpp_insurance.csv&quot;) y=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\ar2.csv&quot;) model = ARIMA(y, order=(2,0,0)) model_fit = model.fit() print(model_fit.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Y No. Observations: 1000 ## Model: ARIMA(2, 0, 0) Log Likelihood -3695.014 ## Date: Wed, 24 Aug 2022 AIC 7398.028 ## Time: 10:54:53 BIC 7417.659 ## Sample: 0 HQIC 7405.489 ## - 1000 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## const -0.1365 0.420 -0.325 0.745 -0.960 0.687 ## ar.L1 0.6406 0.030 21.165 0.000 0.581 0.700 ## ar.L2 -0.3759 0.030 -12.466 0.000 -0.435 -0.317 ## sigma2 94.7853 4.193 22.604 0.000 86.567 103.004 ## =================================================================================== ## Ljung-Box (Q): 28.18 Jarque-Bera (JB): 0.26 ## Prob(Q): 0.92 Prob(JB): 0.88 ## Heteroskedasticity (H): 1.04 Skew: -0.03 ## Prob(H) (two-sided): 0.73 Kurtosis: 3.05 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). lag_test=[3,4,5,6,7,8,9,10] for x in lag_test: sm.stats.acorr_ljungbox(model_fit.resid, lags=[x], model_df=2) ## (array([0.31202552]), array([0.5764399])) ## (array([0.48801976]), array([0.78347989])) ## (array([0.51499794]), array([0.91558429])) ## (array([4.11533556]), array([0.39062185])) ## (array([4.12802033]), array([0.53113539])) ## (array([4.25692091]), array([0.64195223])) ## (array([4.31375708]), array([0.74301224])) ## (array([6.36091615]), array([0.60687265])) ## ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\stats\\diagnostic.py:524: FutureWarning: The value returned will change to a single DataFrame after 0.12 is released. Set return_df to True to use to return a DataFrame now. Set return_df to False to silence this warning. ## warnings.warn(msg, FutureWarning) Trending series import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame import statsmodels.api as sm from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA Daily_High_all=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\ebay9899.csv&quot;) Daily_High=Daily_High_all[&quot;DailyHigh&quot;] Daily_High2=Daily_High.interpolate(option=&#39;spline&#39;) result=adfuller(Daily_High2) print(f&#39;ADF p-value: {result[1]}&#39;) ##Fitting a Random Walk ## ADF p-value: 0.2841870272737812 model = ARIMA(y, order=(0,1,0)) model_fit = model.fit() ###NOT correct, but if you wanted to fit a regression to data x=pd.Series(range(318)) model2=ARIMA(endog=Daily_High2,exog=x,order=[0,0,0]) model2_fit=model2.fit() model2_fit ### Now you can model residuals from the regression (if that is the route you took) ## &lt;statsmodels.tsa.arima.model.ARIMAResultsWrapper object at 0x0000000067D4C1F0&gt; Fitting ARIMA models: import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame import statsmodels.api as sm from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA hurricane=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\hurrican.csv&quot;) max_velocity=hurricane[&quot;MeanVMax&quot;] max2=max_velocity.dropna() ### Testing stationarity result=adfuller(max2) print(f&#39;ADF p-value: {result[1]}&#39;) ### Looks stationary (no trend and no random walk) ## This version needs a stationary time series! ## ADF p-value: 0.0010116374636738128 res1 = sm.tsa.arma_order_select_ic(max2, max_ar=5, max_ma=5,ic=&quot;bic&quot;, trend=&quot;c&quot;) ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available ## warn(&#39;Inverting hessian failed, no bse or cov_params &#39; ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available ## warn(&#39;Inverting hessian failed, no bse or cov_params &#39; ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available ## warn(&#39;Inverting hessian failed, no bse or cov_params &#39; ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:716: RuntimeWarning: divide by zero encountered in divide ## invmacoefs = -np.log((1-macoefs)/(1+macoefs)) ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:689: RuntimeWarning: invalid value encountered in divide ## newparams = ((1-np.exp(-params))/(1+np.exp(-params))).copy() ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:690: RuntimeWarning: invalid value encountered in divide ## tmp = ((1-np.exp(-params))/(1+np.exp(-params))).copy() ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:470: RuntimeWarning: invalid value encountered in subtract ## dx = ((x0 + h) - x0) ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:556: RuntimeWarning: invalid value encountered in double_scalars ## dx = x[i] - x0[i] # Recompute dx as exactly representable number. ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available ## warn(&#39;Inverting hessian failed, no bse or cov_params &#39; ## C:\\PROGRA~3\\ANACON~1\\lib\\site-packages\\statsmodels\\base\\model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available ## warn(&#39;Inverting hessian failed, no bse or cov_params &#39; res1.bic_min_order ## (1, 1) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
