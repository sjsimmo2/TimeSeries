[["arima.html", "Chapter 4 ARIMA 4.1 Stationarity 4.2 Correlation Functions 4.3 AutoRegressive Models (AR) 4.4 Moving Average model (MA) 4.5 White noise 4.6 Examples 4.7 Forecasting 4.8 Trend 4.9 Python Code for ARMA/ARIMA models 4.10 SAS Code for ARMA/ARIMA", " Chapter 4 ARIMA We will not be getting into ARIMA. This chapter is fairly long and covers many different concepts in ARIMA. 4.1 Stationarity Before we can try to model the dependency structure (the AR and MA terms), we must first have a stationary series! The ADF test is one of the most well-known and accepted test for testing stationarity. However, others have also been proposed. Within this document, we will be using the KPSS test. Quotes.ts&lt;-Quotes |&gt; mutate(date = seq(ymd(&#39;2002-01-01&#39;),ymd(&#39;2005-04-21&#39;),by=&#39;months&#39;)) |&gt; mutate(month=yearmonth(date)) |&gt; as_tsibble(index=month) Quotes_train&lt;-Quotes.ts %&gt;% filter(year(date)&lt;2005) autoplot(Quotes_train,Quotes)+labs(title=&quot;Time Series of Monthly Stock quotes&quot;, x=&quot;Time&quot;, y=&quot;Quotes&quot;) The following code looks into stationarity. # Perform the KPSS test Quotes_train |&gt; features(Quotes, unitroot_kpss) ## # A tibble: 1 × 2 ## kpss_stat kpss_pvalue ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.197 0.1 Quotes_train |&gt; features(Quotes, unitroot_ndiffs) ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 0 4.2 Correlation Functions The Acf and the Pacf in R will calculate the autocorrelation (up to the lag you specify) and the partial autocorrelation, respectively. ggAcf(Quotes_train$Quotes,lag=10) ggPacf(Quotes_train$Quotes,lag=10) Since the Hurricane data set needs a difference to be stationary, we will first create the difference column and explore the correlations in that variable. Hurricane.ts&lt;- hurricane %&gt;% as_tsibble(index=Year) Hurricane_train &lt;-Hurricane.ts %&gt;% filter(Year &lt;2000) autoplot(Hurricane_train,MeanVMax)+labs(title=&quot;Time Series of Yearly Mean Velocity for Hurricanes&quot;, x=&quot;Time&quot;, y=&quot;MPH&quot;) Hurricane_train %&gt;% features(MeanVMax,unitroot_ndiffs) ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 1 Hurricane_train &lt;- Hurricane_train %&gt;% mutate(mean_diff=difference(MeanVMax)) Hurricane_train %&gt;% features(mean_diff,unitroot_ndiffs) ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 0 autoplot(Hurricane_train,mean_diff)+labs(title=&quot;Differenced Mean Max Velocity&quot;, x=&quot;Time&quot;, y=&quot;Difference&quot;) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_line()`). 4.3 AutoRegressive Models (AR) AutoRegressive (AR) models involve modeling the lags of Y. We can write an autoregressive model as \\[ Y_{t} = c + \\phi_{1}Y_{t-1}+\\phi_{2}Y_{t-2}+...\\phi_{p}Y_{t-p}+\\epsilon_{t} \\] Where there are p lags of Y. Below is the code to fit an AR(2) model. The order in the Arima function needs the p,d,q values (p=# of AR terms, d=how many differences should be taken and q=# of MA terms). ggAcf(Y[1:731,]) ggPacf(Y[1:731,]) Y.1 &lt;-data.frame(Y) Y.ts&lt;-Y.1 %&gt;% mutate(date = seq(ymd(&#39;2000-01-01&#39;),ymd(&#39;2002-9-26&#39;),by=&#39;day&#39;)) %&gt;% as_tsibble(index=date) Y_train &lt;- Y.ts %&gt;% filter(year(date)&lt;2002) autoplot(Y_train,Y)+labs(title=&quot;Time Series of Simulated Daily series&quot;, x=&quot;Time&quot;, y=&quot;Values&quot;) Y.ARIMA &lt;- Y_train %&gt;% model(ARIMA(Y~pdq(2,0,0)+PDQ(0,0,0))) report(Y.ARIMA) ## Series: Y ## Model: ARIMA(2,0,0) ## ## Coefficients: ## ar1 ar2 ## 0.6399 -0.3838 ## s.e. 0.0342 0.0342 ## ## sigma^2 estimated as 93.75: log likelihood=-2696.14 ## AIC=5398.28 AICc=5398.32 BIC=5412.07 Y.ARIMA %&gt;% residuals() %&gt;% ggAcf() Y.ARIMA %&gt;% residuals() %&gt;% ggPacf() 4.4 Moving Average model (MA) Moving average (MA) models involve modeling the lags of the error. We can write a moving average model as \\[ Y_{t} = c - \\theta_{1}\\epsilon_{t-1}-\\theta_{2}\\epsilon_{t-2}-...\\theta_{q}\\epsilon_{t-q}+\\epsilon_{t} \\] Where there are q lags of \\(\\epsilon\\). Below is code to fit an MA(2) model. ggAcf(x[1:74,]) ggPacf(x[1:74,]) x.1 &lt;-data.frame(x) x.ts&lt;-x.1 %&gt;% mutate(date = seq(ymd(&#39;2000-01-01&#39;),ymd(&#39;2000-4-9&#39;),by=&#39;day&#39;)) %&gt;% as_tsibble(index=date) x_train &lt;- x.ts %&gt;% filter(date &lt; &#39;2000-3-15&#39;) autoplot(x_train,x)+labs(title=&quot;Time Series of Simulated Daily series&quot;, x=&quot;Time&quot;, y=&quot;Values&quot;) x.ARIMA &lt;- x_train %&gt;% model(ARIMA(x~pdq(0,0,2)+PDQ(0,0,0))) report(x.ARIMA) ## Series: x ## Model: ARIMA(0,0,2) ## ## Coefficients: ## ma1 ma2 ## -0.2585 0.4874 ## s.e. 0.1031 0.1063 ## ## sigma^2 estimated as 0.2299: log likelihood=-49.88 ## AIC=105.77 AICc=106.11 BIC=112.68 x.ARIMA %&gt;% residuals() %&gt;% ggAcf() x.ARIMA %&gt;% residuals() %&gt;% ggPacf() 4.5 White noise For residuals to exhibit white noise, they must be “independent” and normally distributed with mean 0 and constant variance. You already know how to assess normality and constant variance, however, we need to focus on assessing “independence”. We can assess if there is significant dependence through the Ljung-Box test (or graphically through ACF and PACF plots). The hypotheses being tested are \\[H_{0}:No\\quad significant\\quad autocorrelation\\\\ H_{A}:Significant\\qquad autocorrletion \\] This should be assessed on a stationary time series. Looking at a stationary time series, going back 10 lags should be sufficient (this will be different when we get to seasonal models). Keep in mind that sample size does matter when assessing significance (adjust significance level accordingly). ### Before fitting model: ljung_box(Y[1:731,], lag = 10, dof=0) ## lb_stat lb_pvalue ## 217.3408 0.0000 ## Note: Y is a vector ### After fitting model: augment(Y.ARIMA) %&gt;% features(.innov,ljung_box, lag=10, dof = 2) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ARIMA(Y ~ pdq(2, 0, 0) + PDQ(0, 0, 0)) 8.50 0.386 ## Note that dof has changed!! 4.6 Examples We will now demonstrate these ideas on two different examples: First example is the Quotes data set: Quotes.ts&lt;-Quotes |&gt; mutate(date = seq(ymd(&#39;2002-01-01&#39;),ymd(&#39;2005-04-21&#39;),by=&#39;months&#39;)) |&gt; mutate(month=yearmonth(date)) |&gt; as_tsibble(index=month) Quotes_train&lt;-Quotes.ts %&gt;% filter(year(date)&lt;2005) autoplot(Quotes_train,Quotes)+labs(title=&quot;Time Series of Monthly Stock quotes&quot;, x=&quot;Time&quot;, y=&quot;Quotes&quot;) Quotes_train %&gt;% gg_tsdisplay(Quotes,plot_type = &#39;partial&#39;) quotes_model &lt;-Quotes_train %&gt;% model(ar1 = ARIMA(Quotes ~ pdq(1,0,0) + PDQ(0,0,0)), ma1 = ARIMA(Quotes ~ pdq(0,0,1) + PDQ(0,0,0)), search1 = ARIMA(Quotes), search2 = ARIMA(Quotes,stepwise = F)) quotes_model2&lt;-as.data.frame(quotes_model) t(quotes_model2) ## [,1] ## ar1 ARIMA(1,0,0) w/ mean ## ma1 ARIMA(0,0,1) w/ mean ## search1 ARIMA(1,0,1) w/ mean ## search2 ARIMA(1,0,1) w/ mean glance(quotes_model) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 4 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 search1 2.54 -66.8 142. 143. 148. ## 2 search2 2.54 -66.8 142. 143. 148. ## 3 ma1 2.75 -68.7 143. 144. 148. ## 4 ar1 2.79 -68.8 144. 144. 148. quotes_model %&gt;% select(search1) %&gt;% residuals() %&gt;% ggAcf() quotes_model %&gt;% select(search1) %&gt;% residuals() %&gt;% ggPacf() quotes_model %&gt;% select(search1) %&gt;% gg_tsresiduals() augment(quotes_model) %&gt;% filter(.model==&#39;search1&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 2) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 search1 3.60 0.892 Second example is the Hurricane data set (mean Maximum velocity): Hurricane.ts&lt;- hurricane %&gt;% as_tsibble(index=Year) Hurricane_train &lt;-Hurricane.ts %&gt;% filter(Year &lt;2000) autoplot(Hurricane_train,MeanVMax)+labs(title=&quot;Time Series of Yearly Mean Velocity for Hurricanes&quot;, x=&quot;Time&quot;, y=&quot;MPH&quot;) Hurricane_train %&gt;% features(MeanVMax,unitroot_ndiffs) ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 1 Hurricane_train &lt;- Hurricane_train %&gt;% mutate(mean_diff=difference(MeanVMax)) Hurricane_train %&gt;% gg_tsdisplay(mean_diff,plot_type = &#39;partial&#39;) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 5 rows containing missing values or values outside the scale range ## (`geom_point()`). hurr_model &lt;-Hurricane_train %&gt;% model(ar3 = ARIMA(MeanVMax ~ 0 + pdq(3,1,0) + PDQ(0,0,0)), ma2 = ARIMA(MeanVMax ~ 0 + pdq(0,1,2) + PDQ(0,1,0)), arima32 = ARIMA(MeanVMax~0 + pdq(3,1,2) + PDQ(0,0,0)), search1 = ARIMA(MeanVMax), search2 = ARIMA(MeanVMax,stepwise = F)) hurr_model2&lt;-as.data.frame(hurr_model) t(hurr_model2) ## [,1] ## ar3 ARIMA(3,1,0) ## ma2 ARIMA(0,1,2) ## arima32 ARIMA(3,1,2) ## search1 ARIMA(1,0,1) w/ mean ## search2 ARIMA(2,0,3) w/ mean glance(hurr_model) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 5 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 arima32 94.6 -539. 1090. 1090. 1108. ## 2 ma2 97.4 -542. 1091. 1091. 1100. ## 3 search2 93.1 -540. 1094. 1095. 1115. ## 4 search1 96.3 -544. 1096. 1096. 1108. ## 5 ar3 108. -549. 1106. 1106. 1118. hurr_model %&gt;% select(ma2) %&gt;% residuals() %&gt;% ggAcf() hurr_model %&gt;% select(ma2) %&gt;% residuals() %&gt;% ggPacf() hurr_model %&gt;% select(ma2) %&gt;% gg_tsresiduals() ## Warning: Removed 2 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). hurr_model %&gt;% select(arima32) %&gt;% residuals() %&gt;% ggAcf() hurr_model %&gt;% select(arima32) %&gt;% residuals() %&gt;% ggPacf() hurr_model %&gt;% select(arima32) %&gt;% gg_tsresiduals() ## Warning: Removed 2 rows containing missing values or values outside the scale range ## (`geom_point()`). ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_bin()`). augment(hurr_model) %&gt;% filter(.model==&#39;arima32&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 5) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 arima32 5.15 0.398 4.7 Forecasting Now let’s forecast each of our models: quotes_model %&gt;% select(search1) %&gt;% fabletools::forecast(h=4) %&gt;% autoplot(Quotes_train) quotes_for&lt;-quotes_model %&gt;% select(search1) %&gt;% fabletools::forecast(h=4) quotes_resid&lt;-Quotes$Quotes[37:40]-quotes_for$.mean MAPE&lt;-mean(abs(quotes_resid/Quotes$Quotes[37:40])) MAE&lt;-mean(abs(quotes_resid)) MAPE ## [1] 0.2330841 MAE ## [1] 3.952702 hurr_model %&gt;% select(arima32) %&gt;% fabletools::forecast(h=8) %&gt;% autoplot(Hurricane_train) hurr_for&lt;-hurr_model %&gt;% select(arima32) %&gt;% fabletools::forecast(h=8) hurr_resid&lt;-hurricane$MeanVMax[150:157]-hurr_for$.mean MAPE&lt;-mean(abs(hurr_resid/hurricane$MeanVMax[150:157])) MAE&lt;-mean(abs(hurr_resid)) MAPE ## [1] 0.06067555 MAE ## [1] 5.986266 4.8 Trend We will now take a look at trending time series. We will use the Consume and Raleigh Housing prices index as two examples. Consumer example using differences for trend: consume.ts&lt;- consume |&gt; mutate(date2=my(date))|&gt; mutate(month=yearmonth(date2)) |&gt; as_tsibble(index=month) consume_train&lt;-consume.ts %&gt;% filter(year(date2)&lt;1990) autoplot(consume_train,Disposable_income)+labs(title=&quot;Time Series of Monthly Disposable Income&quot;, x=&quot;Time&quot;, y=&quot;Thousands of Dollars&quot;) ndiffs(consume_train$Disposable_income) ## [1] 1 consume_train&lt;- consume_train %&gt;% mutate(income_diff = difference(Disposable_income)) autoplot(consume_train,income_diff)+labs(title=&quot;Time Series of Differenced Monthly Disposable Income&quot;, x=&quot;Time&quot;, y=&quot;Differences&quot;) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_line()`). consume_train %&gt;% gg_tsdisplay(income_diff,plot_type = &#39;partial&#39;) ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 1 row containing missing values or values outside the scale range ## (`geom_point()`). consume_model &lt;-consume_train %&gt;% model(ar1 = ARIMA(Disposable_income ~ pdq(1,1,0) + PDQ(0,0,0)), ma1 = ARIMA(Disposable_income ~ pdq(0,1,1) + PDQ(0,0,0)), ar6 = ARIMA(Disposable_income ~ pdq(6,1,0) + PDQ(0,0,0)), ma6 = ARIMA(Disposable_income ~ pdq(0,1,6) + PDQ(0,0,0)), search1 = ARIMA(Disposable_income), search2 = ARIMA(Disposable_income,stepwise = F)) consume_model2&lt;-as.data.frame(consume_model) t(consume_model2) ## [,1] ## ar1 ARIMA(1,1,0) w/ drift ## ma1 ARIMA(0,1,1) w/ drift ## ar6 ARIMA(6,1,0) w/ drift ## ma6 ARIMA(0,1,6) ## search1 ARIMA(0,1,1) w/ drift ## search2 ARIMA(0,1,1) w/ drift glance(consume_model) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 6 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ma1 546. -397. 799. 800. 807. ## 2 search1 546. -397. 799. 800. 807. ## 3 search2 546. -397. 799. 800. 807. ## 4 ar6 520. -392. 800. 802. 820. ## 5 ar1 571. -399. 803. 803. 811. ## 6 ma6 610. -400. 814. 815. 831. consume_modelt1 &lt;-consume_train %&gt;% model(arima11 = ARIMA(Disposable_income ~ pdq(1,1,1) + PDQ(0,0,0)), arima21 = ARIMA(Disposable_income ~ pdq(2,1,1) + PDQ(0,0,0)), arima20 = ARIMA(Disposable_income ~ pdq(2,1,0) + PDQ(0,0,0)), arima12 = ARIMA(Disposable_income ~ pdq(1,1,2) + PDQ(0,0,0)), arima30 = ARIMA(Disposable_income ~ pdq(3,1,0) + PDQ(0,0,0)) ) ## Warning: It looks like you&#39;re trying to fully specify your ARIMA model but have not said if a constant should be included. ## You can include a constant using `ARIMA(y~1)` to the formula or exclude it by adding `ARIMA(y~0)`. ## It looks like you&#39;re trying to fully specify your ARIMA model but have not said if a constant should be included. ## You can include a constant using `ARIMA(y~1)` to the formula or exclude it by adding `ARIMA(y~0)`. ## Warning: 1 error encountered for arima21 ## [1] Could not find an appropriate ARIMA model. ## This is likely because automatic selection does not select models with characteristic roots that may be numerically unstable. ## For more details, refer to https://otexts.com/fpp3/arima-r.html#plotting-the-characteristic-roots ## Warning: 1 error encountered for arima12 ## [1] Could not find an appropriate ARIMA model. ## This is likely because automatic selection does not select models with characteristic roots that may be numerically unstable. ## For more details, refer to https://otexts.com/fpp3/arima-r.html#plotting-the-characteristic-roots consume_modelt2&lt;-as.data.frame(consume_modelt1) t(consume_modelt2) ## [,1] ## arima11 ARIMA(1,1,1) ## arima21 NULL model ## arima20 ARIMA(2,1,0) w/ drift ## arima12 NULL model ## arima30 ARIMA(3,1,0) w/ drift glance(consume_modelt1) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 3 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 arima20 551. -397. 801. 802. 811. ## 2 arima30 548. -396. 802. 802. 814. ## 3 arima11 665. -405. 816. 817. 824. consume_model %&gt;% select(ar6) %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) consume_model %&gt;% select(ar6) %&gt;% residuals() %&gt;% ggPacf(lag.max = 10) consume_model %&gt;% select(ar6) %&gt;% gg_tsresiduals() augment(consume_model) %&gt;% filter(.model==&#39;ar6&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 6) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ar6 3.21 0.523 pred_ar6 &lt;- consume_model %&gt;% select(ar6) %&gt;% fabletools::forecast(h=6) error_ar6 &lt;- consume$Disposable_income[89:94] - pred_ar6$.mean MAPE_ar6 &lt;-mean(abs(error_ar6/consume$Disposable_income[89:94])) MAE_ar6 &lt;- mean(abs(error_ar6)) consume_model %&gt;% select(ar6) %&gt;% fabletools::forecast(h=6) %&gt;% autoplot(consume_train) pred_ma1 &lt;- consume_model %&gt;% select(ma1) %&gt;% fabletools::forecast(h=6) error_ma1 &lt;- consume$Disposable_income[89:94] - pred_ma1$.mean MAPE_ma1 &lt;-mean(abs(error_ma1/consume$Disposable_income[89:94])) MAE_ma1 &lt;- mean(abs(error_ma1)) consume_model %&gt;% select(ma1) %&gt;% fabletools::forecast(h=6) %&gt;% autoplot(consume_train) Raleigh example using differences: Raleigh.ts&lt;- Raleigh %&gt;% mutate(quarter=yearquarter(DATE)) %&gt;% as_tsibble(index=quarter) Raleigh_train &lt;-Raleigh.ts %&gt;% filter(quarter &lt;yearquarter(&quot;2023 Q1&quot;)) autoplot(Raleigh_train,price_index)+labs(title=&quot;Time Series of Quarterly Housing price Index for Raleigh-Cary&quot;, x=&quot;Time&quot;, y=&quot;Index&quot;) Raleigh_train %&gt;% features(price_index,unitroot_ndiffs) ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 2 Raleigh_train &lt;- Raleigh_train %&gt;% mutate(diff_price=difference(difference(price_index))) Raleigh_train %&gt;% gg_tsdisplay(diff_price,plot_type = &#39;partial&#39;) ## Warning: Removed 2 rows containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 2 rows containing missing values or values outside the scale range ## (`geom_point()`). Raleigh_model &lt;-Raleigh_train %&gt;% model( ma5 = ARIMA(price_index ~ pdq(0,2,5)+ PDQ(0,0,0)+0), ar2 = ARIMA(price_index ~ pdq(2,2,0)+ PDQ(0,0,0)+0), ma2 = ARIMA(price_index ~ pdq(0,2,2)+ PDQ(0,0,0)+0), search1 = ARIMA(price_index~PDQ(0,0,0)), search2 = ARIMA(price_index,stepwise = FALSE) ) Raleigh_model2&lt;-as.data.frame(Raleigh_model) t(Raleigh_model2) ## [,1] ## ma5 ARIMA(0,2,5) ## ar2 ARIMA(2,2,0) ## ma2 ARIMA(0,2,2) ## search1 ARIMA(1,2,3) ## search2 ARIMA(0,2,5) glance(Raleigh_model) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 5 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ma5 7.65 -219. 451. 452. 466. ## 2 search2 7.65 -219. 451. 452. 466. ## 3 search1 8.36 -223. 455. 456. 468. ## 4 ar2 9.50 -229. 464. 464. 471. ## 5 ma2 10.1 -231. 468. 469. 476. Raleigh_model %&gt;% select(search1) %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) Raleigh_model %&gt;% select(search1) %&gt;% residuals() %&gt;% ggPacf(lag.max = 10) Raleigh_model %&gt;% select(search1) %&gt;% gg_tsresiduals() augment(Raleigh_model) %&gt;% filter(.model==&#39;search1&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 4) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 search1 7.76 0.257 pred_arima123 &lt;- Raleigh_model %&gt;% select(search1) %&gt;% fabletools::forecast(h=5) error_arima123 &lt;- Raleigh.ts$price_index[93:97] - pred_arima123$.mean MAPE_arima123 &lt;-mean(abs(error_arima123/Raleigh.ts$price_index[93:97])) MAE_arima123 &lt;- mean(abs(error_arima123)) Raleigh_model %&gt;% select(search1) %&gt;% fabletools::forecast(h=5) %&gt;% autoplot(Raleigh_train) pred_data &lt;- tibble( quarter = yearquarter(seq.Date(from = as.Date(&quot;2023-01-01&quot;), to = as.Date(&quot;2024-01-01&quot;), by = &quot;quarter&quot;)), value = pred_arima123$.mean ) test_data &lt;- tibble( quarter = yearquarter(seq.Date(from = as.Date(&quot;2023-01-01&quot;), to = as.Date(&quot;2024-01-01&quot;), by = &quot;quarter&quot;)), value = Raleigh.ts$price_index[93:97] ) ggplot() + geom_line(data = test_data, aes(x = quarter, y = value), color = &quot;blue&quot;, linetype = &quot;solid&quot;) + geom_line(data = pred_data, aes(x = quarter, y = value), color = &quot;orange&quot;, linetype = &quot;dashed&quot;) + labs(title = &quot;Predicted versus Actual values&quot;, x = &quot;Quarter&quot;, y = &quot;Price Index&quot;) + theme_minimal() Using the consumer data set and fitting a linear trend line: consume_linear &lt;-consume_train %&gt;% model(trend1 = ARIMA(Disposable_income~ trend() + pdq(0,0,0) + PDQ(0,0,0)+1) ) report(consume_linear) ## Series: Disposable_income ## Model: LM w/ ARIMA(0,0,0) errors ## ## Coefficients: ## trend() intercept ## 7.8743 2368.4594 ## s.e. 0.1168 5.9841 ## ## sigma^2 estimated as 792.5: log likelihood=-417.56 ## AIC=841.12 AICc=841.41 BIC=848.56 fitted_values &lt;- fitted(consume_linear) # Plot the original data and fitted values autoplot(consume_train, Disposable_income) + autolayer(fitted_values, .fitted, color = &quot;blue&quot;, linetype = &quot;dashed&quot;) + labs(title = &quot;Fitted Values from Linear Regression Model for Disposable Income&quot;, x = &quot;Time&quot;, y = &quot;Dollars (000)&quot;) + theme_minimal() consume_linear %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) consume_linear %&gt;% residuals() %&gt;% ggPacf(lag.max = 10) consume_linear &lt;-consume_train %&gt;% model(trend1 = ARIMA(Disposable_income~ trend() + pdq(6,0,0) + PDQ(0,0,0)+1), trend2 = ARIMA(Disposable_income ~ trend() + PDQ(0,0,0) +1) ) consume_linear2&lt;-as.data.frame(consume_linear) t(consume_linear2) ## [,1] ## trend1 LM w/ ARIMA(6,0,0) errors ## trend2 LM w/ ARIMA(1,0,0) errors glance(consume_linear) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 2 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 trend2 504. -397. 803. 803. 813. ## 2 trend1 486. -393. 805. 807. 827. Comparing the random walk with drift to the linear trend time series model for the consumer data set: consume_linear %&gt;% select(trend1) %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) consume_linear %&gt;% select(trend1) %&gt;% residuals() %&gt;% ggPacf(lag.max = 10) consume_linear %&gt;% select(trend1) %&gt;% gg_tsresiduals() augment(consume_linear) %&gt;% filter(.model==&#39;trend1&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 6) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 trend1 3.20 0.524 pred_lm &lt;- consume_linear %&gt;% select(trend1) %&gt;% fabletools::forecast(h=6) consume_linear %&gt;% select(trend1) %&gt;% fabletools::forecast(h=6) %&gt;% autoplot(consume_train) error_lm &lt;- consume$Disposable_income[89:94] - pred_lm$.mean MAPE_lm &lt;-mean(abs(error_lm/consume$Disposable_income[89:94])) MAE_lm &lt;- mean(abs(error_lm)) pred_rw &lt;- tibble( month = yearmonth(seq.Date(from = as.Date(&quot;1990-01-01&quot;), to = as.Date(&quot;1990-06-01&quot;), by = &quot;month&quot;)), value = pred_ar6$.mean ) pred_lm2 &lt;- tibble( month = yearmonth(seq.Date(from = as.Date(&quot;1990-01-01&quot;), to = as.Date(&quot;1990-06-01&quot;), by = &quot;month&quot;)), value = pred_lm$.mean ) test_data &lt;- tibble( month = yearmonth(seq.Date(from = as.Date(&quot;1990-01-01&quot;), to = as.Date(&quot;1990-06-01&quot;), by = &quot;month&quot;)), value = consume.ts$Disposable_income[89:94] ) combined_data &lt;- bind_rows( test_data %&gt;% mutate(Line = &quot;Actual&quot;), pred_rw %&gt;% mutate(Line = &quot;Random Walk&quot;), pred_lm2 %&gt;% mutate(Line = &quot;Linear Model&quot;) ) # Plot the data with a legend ggplot(combined_data, aes(x = month, y = value, color = Line)) + geom_line(linetype = &quot;solid&quot;) + labs(title = &quot;Predicted versus Actual values&quot;, x = &quot;Date&quot;, y = &quot;Disposable Income (000)&quot;, color = &quot;Legend&quot;) + theme_minimal() Fitting a trend line to the Raleigh data set: Raleigh_linear &lt;-Raleigh_train %&gt;% model(trend1 = ARIMA(price_index~ trend() + pdq(0,0,0) + PDQ(0,0,0)+1) ) Raleigh_linear %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) Raleigh_linear %&gt;% residuals() %&gt;% ggPacf(lag.max = 10) Raleigh_linear &lt;-Raleigh_train %&gt;% model(trend1 = ARIMA(price_index~ trend() + pdq(2,0,0) + PDQ(0,0,0)+1), trend2 = ARIMA(price_index ~ trend() + PDQ(0,0,0) + 1), trend3 = ARIMA(price_index ~ trend() + PDQ(0,0,0) + 1,stepwise = FALSE) ) Raleigh_linear2&lt;-as.data.frame(Raleigh_linear) t(Raleigh_linear2) ## [,1] ## trend1 LM w/ ARIMA(2,0,0) errors ## trend2 LM w/ ARIMA(2,0,2) errors ## trend3 LM w/ ARIMA(1,0,4) errors glance(Raleigh_linear) %&gt;% arrange(AICc) %&gt;% select(.model:BIC) ## # A tibble: 3 × 6 ## .model sigma2 log_lik AIC AICc BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 trend3 7.45 -224. 465. 466. 485. ## 2 trend2 8.53 -230. 474. 475. 491. ## 3 trend1 10.5 -239. 488. 489. 501. Raleigh_linear %&gt;% select(trend2) %&gt;% residuals() %&gt;% ggAcf(lag.max = 10) Raleigh_linear %&gt;% select(trend2) %&gt;%residuals() %&gt;% ggPacf(lag.max = 10) augment(Raleigh_linear) %&gt;% filter(.model==&#39;trend2&#39;) %&gt;% features(.innov,ljung_box, lag=10, dof = 4) ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 trend2 9.50 0.147 Comparing the Raleigh data set using a random walk with drift to the trend model: pred_lm &lt;- Raleigh_linear %&gt;% select(trend2) %&gt;% fabletools::forecast(h=5) error_lm &lt;- Raleigh.ts$price_index[93:97] - pred_lm$.mean MAPE_lm &lt;-mean(abs(error_lm/Raleigh.ts$price_index[93:97])) MAE_lm &lt;- mean(abs(error_lm)) pred_rw &lt;- tibble( quarter = yearquarter(seq.Date(from = as.Date(&quot;2023-01-01&quot;), to = as.Date(&quot;2024-01-01&quot;), by = &quot;quarter&quot;)), value = pred_arima123$.mean ) pred_lm2 &lt;- tibble( quarter = yearquarter(seq.Date(from = as.Date(&quot;2023-01-01&quot;), to = as.Date(&quot;2024-01-01&quot;), by = &quot;quarter&quot;)), value = pred_lm$.mean ) test_data &lt;- tibble( quarter = yearquarter(seq.Date(from = as.Date(&quot;2023-01-01&quot;), to = as.Date(&quot;2024-01-01&quot;), by = &quot;quarter&quot;)), value = Raleigh.ts$price_index[93:97] ) combined_data &lt;- bind_rows( test_data %&gt;% mutate(Line = &quot;Actual&quot;), pred_rw %&gt;% mutate(Line = &quot;Random Walk&quot;), pred_lm2 %&gt;% mutate(Line = &quot;Linear Model&quot;) ) # Plot the data with a legend ggplot(combined_data, aes(x = quarter, y = value, color = Line)) + geom_line(linetype = &quot;solid&quot;) + labs(title = &quot;Predicted versus Actual values&quot;, x = &quot;Date&quot;, y = &quot;Raleigh Price Index&quot;, color = &quot;Legend&quot;) + theme_minimal() 4.9 Python Code for ARMA/ARIMA models import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA quotes=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\fpp_insurance.csv&quot;) y=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\ar2.csv&quot;) result=adfuller(quotes[&quot;Quotes&quot;]) print(f&#39;ADF p-value: {result[1]}&#39;) ## ADF p-value: 0.010194998749727997 plot_acf(quotes[&quot;Quotes&quot;],lags=12) pyplot.show() plot_pacf(quotes[&quot;Quotes&quot;],lags=12) pyplot.show ## &lt;function make_python_function.&lt;locals&gt;.python_function at 0x000001EE61741B40&gt; model = ARIMA(y, order=(2,0,0)) model_fit = model.fit() print(model_fit.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Y No. Observations: 1000 ## Model: ARIMA(2, 0, 0) Log Likelihood -3695.014 ## Date: Tue, 20 Aug 2024 AIC 7398.028 ## Time: 13:23:35 BIC 7417.659 ## Sample: 0 HQIC 7405.489 ## - 1000 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## const -0.1365 0.420 -0.325 0.745 -0.960 0.687 ## ar.L1 0.6406 0.030 21.165 0.000 0.581 0.700 ## ar.L2 -0.3759 0.030 -12.466 0.000 -0.435 -0.317 ## sigma2 94.7853 4.193 22.604 0.000 86.567 103.004 ## =================================================================================== ## Ljung-Box (L1) (Q): 0.02 Jarque-Bera (JB): 0.26 ## Prob(Q): 0.89 Prob(JB): 0.88 ## Heteroskedasticity (H): 1.04 Skew: -0.03 ## Prob(H) (two-sided): 0.73 Kurtosis: 3.05 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). residuals = DataFrame(model_fit.resid) residuals.plot() pyplot.show() print(residuals.describe()) ## 0 ## count 1000.000000 ## mean -0.001313 ## std 9.747534 ## min -33.282545 ## 25% -6.475670 ## 50% 0.117391 ## 75% 6.510636 ## max 30.318100 plot_acf(residuals,lags=12) pyplot.show() plot_pacf(residuals,lags=12) pyplot.show() Checking for white noise: The first value in the Ljung-Box test is the test statistic and the second value is the p-value. import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame import statsmodels.api as sm from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA quotes=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\fpp_insurance.csv&quot;) y=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\ar2.csv&quot;) model = ARIMA(y, order=(2,0,0)) model_fit = model.fit() print(model_fit.summary()) ## SARIMAX Results ## ============================================================================== ## Dep. Variable: Y No. Observations: 1000 ## Model: ARIMA(2, 0, 0) Log Likelihood -3695.014 ## Date: Tue, 20 Aug 2024 AIC 7398.028 ## Time: 13:23:36 BIC 7417.659 ## Sample: 0 HQIC 7405.489 ## - 1000 ## Covariance Type: opg ## ============================================================================== ## coef std err z P&gt;|z| [0.025 0.975] ## ------------------------------------------------------------------------------ ## const -0.1365 0.420 -0.325 0.745 -0.960 0.687 ## ar.L1 0.6406 0.030 21.165 0.000 0.581 0.700 ## ar.L2 -0.3759 0.030 -12.466 0.000 -0.435 -0.317 ## sigma2 94.7853 4.193 22.604 0.000 86.567 103.004 ## =================================================================================== ## Ljung-Box (L1) (Q): 0.02 Jarque-Bera (JB): 0.26 ## Prob(Q): 0.89 Prob(JB): 0.88 ## Heteroskedasticity (H): 1.04 Skew: -0.03 ## Prob(H) (two-sided): 0.73 Kurtosis: 3.05 ## =================================================================================== ## ## Warnings: ## [1] Covariance matrix calculated using the outer product of gradients (complex-step). lag_test=[3,4,5,6,7,8,9,10] for x in lag_test: sm.stats.acorr_ljungbox(model_fit.resid, lags=[x], model_df=2) ## lb_stat lb_pvalue ## 3 0.312026 0.57644 ## lb_stat lb_pvalue ## 4 0.48802 0.78348 ## lb_stat lb_pvalue ## 5 0.514998 0.915584 ## lb_stat lb_pvalue ## 6 4.115336 0.390622 ## lb_stat lb_pvalue ## 7 4.12802 0.531135 ## lb_stat lb_pvalue ## 8 4.256921 0.641952 ## lb_stat lb_pvalue ## 9 4.313757 0.743012 ## lb_stat lb_pvalue ## 10 6.360916 0.606873 Fitting ARIMA models. import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib import pyplot from pandas import DataFrame import statsmodels.api as sm from statsmodels.tsa.stattools import adfuller from statsmodels.graphics.tsaplots import plot_acf from statsmodels.graphics.tsaplots import plot_pacf from statsmodels.tsa.arima.model import ARIMA import pmdarima as pm hurricane=pd.read_csv(&quot;Q:\\\\My Drive\\\\Fall 2017 - Time Series\\\\DataR\\\\hurrican.csv&quot;) max_velocity=hurricane[&quot;MeanVMax&quot;] max2=max_velocity.dropna() ### Testing stationarity result=adfuller(max2) print(f&#39;ADF p-value: {result[1]}&#39;) ## ADF p-value: 0.0010116374636738128 ### Same result as auto.arima in R! model1=pm.auto_arima(max2, start_p=0,start_q=0,max_p=5,max_q=5,seasonal=False) model1.summary() SARIMAX Results Dep. Variable: y No. Observations: 155 Model: SARIMAX(0, 1, 1) Log Likelihood -570.040 Date: Tue, 20 Aug 2024 AIC 1144.080 Time: 13:23:37 BIC 1150.154 Sample: 0 HQIC 1146.547 - 155 Covariance Type: opg coef std err z P>|z| [0.025 0.975] ma.L1 -0.9050 0.036 -25.036 0.000 -0.976 -0.834 sigma2 95.0278 10.416 9.123 0.000 74.612 115.443 Ljung-Box (L1) (Q): 0.05 Jarque-Bera (JB): 0.30 Prob(Q): 0.81 Prob(JB): 0.86 Heteroskedasticity (H): 2.10 Skew: 0.08 Prob(H) (two-sided): 0.01 Kurtosis: 3.15 Warnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step). # Force d=0 model2=pm.auto_arima(max2, start_p=0,start_q=0,max_p=5,max_q=5,d=0,seasonal=False) model2.summary() SARIMAX Results Dep. Variable: y No. Observations: 155 Model: SARIMAX(1, 0, 1) Log Likelihood -574.278 Date: Tue, 20 Aug 2024 AIC 1156.556 Time: 13:23:39 BIC 1168.729 Sample: 0 HQIC 1161.500 - 155 Covariance Type: opg coef std err z P>|z| [0.025 0.975] intercept 26.5825 20.863 1.274 0.203 -14.308 67.473 ar.L1 0.7082 0.228 3.103 0.002 0.261 1.156 ma.L1 -0.5717 0.281 -2.031 0.042 -1.123 -0.020 sigma2 97.3309 11.556 8.423 0.000 74.682 119.979 Ljung-Box (L1) (Q): 0.23 Jarque-Bera (JB): 2.12 Prob(Q): 0.63 Prob(JB): 0.35 Heteroskedasticity (H): 1.75 Skew: 0.29 Prob(H) (two-sided): 0.05 Kurtosis: 2.95 Warnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step). 4.10 SAS Code for ARMA/ARIMA AUGMENTED DICKEY-FULLER TESTING proc arima data=Time.fpp_insurance plot=all;   identify var=quotes nlag=10 stationarity=(adf=2);   identify var=quotes(1) nlag=10 stationarity=(adf=2);   run; quit; CORRELATION FUNCTIONS Notice no model statement!   proc arima data=Time.ar2 plot(unpack)=all;   identify var=y nlag=10 outcov=Corr;   estimate method=ML;   run; quit; BUILDING AN AUTOREGRESSIVE MODEL Fit an AR2 model   proc arima data=Time.AR2 plot=all;   identify var=y nlag=10;   estimate p=2 method=ML;   run; quit;   Add another estimate statement proc arima data=Time.AR2 plot=all; identify var=y nlag=10; estimate p=(2) method=ML; estimate p=(1,2,4) method=ML; run; quit;   BUILDING A MOVING AVERAGE MODEL proc arima data=Time.ma2;   identify var=x;   estimate q=2 method=ML;   run; quit;   Need to check for how to take care of trend proc arima data=Time.Ebay9899 plot=all;   identify var=DailyHigh nlag=10 stationarity=(adf=2);   run; quit; It is a random walk!! The way to model a random walk is by using differences   proc arima data=Time.Ebay9899 plot=all;   identify var=DailyHigh(1) nlag=10 stationarity=(adf=2);   run; quit; BUILDING AN AUTOREGRESSIVE MOVING AVERAGE MODEL   (AUTOMATIC SELECTION TECHNIQUES)   Fit an ARIMA model   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=12 stationarity=(adf=2);   run; quit;   Model identification with minimum information criterion (MINIC)   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=12 minic P=(0:12) Q=(0:12);   run; quit;   Model identification with smallest canonical correlation (SCAN);   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=12 scan P=(0:12) Q=(0:12);   run; quit;   Model identificaiton with extended sample autocorrelation function (ESACF)   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=12 esacf P=(0:12) Q=(0:12);   run; quit;   Create estimates with our ARIMA model p=2, q=3   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=12;   estimate p=2 q=3 method=ML;   run; quit; FORECASTING   proc arima data=Time.Hurricanes plot=all;   identify var=MeanVMax nlag=10 ;   estimate p=2 q=3 method=ML;   forecast lead=10;   run; quit; "]]
